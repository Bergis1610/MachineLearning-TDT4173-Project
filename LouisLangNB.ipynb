{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Louis Long Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emil studid & Louis studid, teamname "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table of contents:\n",
    "1. Exploratory data analysis\n",
    "2. Models/Predictors\n",
    "    - Model 1\n",
    "    - Model 2\n",
    "    - model ...\n",
    "3. Feature Engineering \n",
    "    - Lime\n",
    "    - feature importance\n",
    "    - PDP\n",
    "4. Model Interpretations\n",
    "5. Improved models (possibly)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ___________ _0. Setup_ ___________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.ensemble as ensemble\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import log_loss, mean_squared_error, mean_squared_log_error\n",
    "from verstack import LGBMTuner\n",
    "\n",
    "#from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeResultToFile(test_data, pred_data, nameOfFile='namelessSubmission'):\n",
    "    submission = pd.DataFrame()\n",
    "    submission['id'] = test_data['store_id']\n",
    "    submission['predicted'] = np.asarray(pred_data)\n",
    "    submission.to_csv('submissionFiles/'+ nameOfFile+'.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred):\n",
    "    return metrics.mean_squared_log_error(y_true, y_pred)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ___________ _1. Exploratory Data Analysis_ ___________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA Notes\n",
    "- [ ] Search domain knowledge\n",
    "- [ ] Check if the data is intuitive\n",
    "- [ ] Understand how the data was generated\n",
    "- [ ] Explore individual features\n",
    "    - [x] Agencies\n",
    "    - [x] stores with 0 revenue\n",
    "    - [x] food and drink stores and grovery stores\n",
    "- [ ] Explore pairs and groups\n",
    "    - [x] Store type vs revenue\n",
    "- [ ] Clean up features\n",
    "    - [x] remove 2016\n",
    "    - [x] remove outliers\n",
    "    - [x] remove 0 revenue rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_train = pd.read_csv('data/stores_train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#report = ProfileReport(stores_train)\n",
    "#report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore revenue based on store type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plaace_hierarchy = pd.read_csv('data/plaace_hierarchy.csv')\n",
    "stores_with_hierarchy = stores_train.merge(plaace_hierarchy, how='left', on='plaace_hierarchy_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,6))\n",
    "plt.gcf().set_dpi(600)\n",
    "plt.xticks(rotation=90)\n",
    "sns.violinplot(x='lv2_desc',y='revenue',data=stores_with_hierarchy).set_title(\"Revenue on store type\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "further exploration of agencie store type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_with_hierarchy[stores_with_hierarchy[\"lv2_desc\"]==\"Agencies\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further exploration of \"Food and drink\" type stores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "sns.violinplot(x='lv3_desc',y='revenue',data=stores_with_hierarchy[stores_with_hierarchy[\"lv2_desc\"]==\"Food and drinks\"]).set_title(\"Food and drinks violin plot\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore retailers with 0 revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_with_hierarchy[stores_with_hierarchy[\"revenue\"]==0.0].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All retailers and their cooresponding revenue, the plot is to visually check for outliers, clearly there are som outliers as can be seen in the plot below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(stores_train['store_id'], stores_train['revenue'],'o')\n",
    "plt.figure(figsize=(30,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove columns function - example: year is a const value and has no effect on the end result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_columns(dataSet, columns):\n",
    "    for column in columns:\n",
    "        dataSet.drop(column, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_columns(stores_train,['year'])\n",
    "stores_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove retailers with 0 revenue function - might be handy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_retailers_with_0_revenue(dataSet):\n",
    "    dataSet.drop(dataSet[dataSet['revenue']==0.0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove_retailers_with_0_revenue(stores_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing outliers\n",
    "\n",
    "Plotting all retailers based on storetype before and after trimming to confirm that outliers actually has been removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for store_type in stores_with_hierarchy['lv2_desc'].unique():\n",
    "    plt.figure(figsize=(12,2))\n",
    "    sns.violinplot(x='lv3_desc',y='revenue',data=stores_with_hierarchy[stores_with_hierarchy[\"lv2_desc\"]==store_type]).set_title(f\"{store_type} violin plot\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove-outliers-function for the relationship between store type and revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantile_storeType_vs_revenue(stores, lower, upper):\n",
    "    for store_type in stores['plaace_hierarchy_id'].unique():\n",
    "        data = stores[stores['plaace_hierarchy_id']==store_type]\n",
    "        upper_treshold = data['revenue'].quantile(upper)\n",
    "        lower_treshold = data['revenue'].quantile(lower)\n",
    "        stores.drop(stores[(stores['plaace_hierarchy_id']==store_type) & (stores['revenue']>upper_treshold)].index, inplace=True)\n",
    "        stores.drop(stores[(stores['plaace_hierarchy_id']==store_type) & (stores['revenue']<lower_treshold)].index, inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_storeType_vs_revenue(stores_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot after removing outliers\n",
    "\n",
    "you can see in the plot below that the outliers has been removed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plaace_hierarchy = pd.read_csv('data/plaace_hierarchy.csv')\n",
    "stores_with_hierarchy = stores_train.merge(plaace_hierarchy, how='left', on='plaace_hierarchy_id')\n",
    "for store_type in stores_with_hierarchy['lv2_desc'].unique():\n",
    "    plt.figure(figsize=(12,2))\n",
    "    sns.violinplot(x='lv3_desc',y='revenue',data=stores_with_hierarchy[stores_with_hierarchy[\"lv2_desc\"]==store_type]).set_title(f\"{store_type} violin plot\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### comparing test set to training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_train = pd.read_csv('data/stores_train.csv')\n",
    "stores_test = pd.read_csv('data/stores_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comparing coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,9), dpi=600)\n",
    "plt.scatter(stores_train['lon'],stores_train['lat'], label=\"traing\",color='red')\n",
    "plt.scatter(stores_test['lon'], stores_test['lat'], alpha=0.2, label=\"test\", color=\"blue\")\n",
    "plt.legend(fontsize=10,ncol=2)\n",
    "plt.xlabel(\"Latitude\")\n",
    "plt.ylabel(\"Longitude\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(projection='3d')\n",
    "ax1.scatter(stores_train['lat'],stores_train['lon'],stores_train['revenue'])\n",
    "ax1.set_xlabel('Lat')\n",
    "ax1.set_ylabel('Lon')\n",
    "ax1.set_zlabel('Revenue')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine whether a store occurs in multiple datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stores_that_are_in_both_sets(df1, df2):\n",
    "    \n",
    "    duplicate_set = pd.merge(df1,df2, how='inner', on='store_name')\n",
    "    return duplicate_set\n",
    "\n",
    "stores_train = pd.read_csv('data/stores_train.csv')\n",
    "stores_test = pd.read_csv('data/stores_test.csv')\n",
    "stores_extra = pd.read_csv('data/stores_extra.csv')\n",
    "\n",
    "dup = stores_that_are_in_both_sets(stores_test, stores_train)\n",
    "dup.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.___________ _Machine Learning Models and Predictions_ ___________\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Louis modeller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _____ LightGBM _____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_DType_LGBM(dFrame):\n",
    "    X = pd.DataFrame()\n",
    "    for col_name in dFrame:\n",
    "        if dFrame[col_name].dtypes == 'object':\n",
    "            X[col_name] = dFrame[col_name].astype('category')\n",
    "        else:\n",
    "            X[col_name] = dFrame[col_name]\n",
    "    \n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_train = pd.read_csv('data/stores_train.csv')\n",
    "\n",
    "# select prefered columns\n",
    "remove_columns(stores_train, ['store_id','year','store_name','sales_channel_name','grunnkrets_id','address'])\n",
    "\n",
    "# Divide data into train and test set\n",
    "temp_x = stores_train.drop('revenue', axis=1)\n",
    "temp_y = stores_train['revenue']\n",
    "\n",
    "_, x_test, _, y_true = train_test_split(temp_x, temp_y, test_size=0.20, random_state=1)\n",
    "\n",
    "\n",
    "# Preprocess/Clean data\n",
    "quantile_storeType_vs_revenue(stores_train,0.02, 0.86)\n",
    "#remove_retailers_with_0_revenue(stores_train)\n",
    "\n",
    "# Divide data into x and y train, and test data for submission\n",
    "x_train = stores_train.drop('revenue', axis=1)\n",
    "y_train = stores_train['revenue']\n",
    "\n",
    "\n",
    "# Convert from object type to numerical\n",
    "x_train = convert_DType_LGBM(x_train)\n",
    "x_test = convert_DType_LGBM(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "LGBM =LGBMRegressor()\n",
    "#LGBM = lgb.LGBMRegressor(reg_alpha=0.2739452484147049, reg_lambda=9.205287883979267, colsample_bytree= 0.6, subsample=0.8, learning_rate= 0.014, max_depth= 100, num_leaves=449, min_child_samples=242)\n",
    "# fitting\n",
    "LGBM.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting the training data set as a pin pointer\n",
    "pred = LGBM.predict(x_test)\n",
    "for i in range(len(pred)):\n",
    "    if pred[i] < 0.0:\n",
    "        print(i)\n",
    "        pred[i] = 0.0\n",
    "print(rmsle(y_true,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previous rmse scores gave the following kaggle scores:\n",
    "# - 0.74281469137304 rmse resulted in: 0.75490 on kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autotesting percentile cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10,1):\n",
    "    stores_train = pd.read_csv('data/stores_train.csv')\n",
    "\n",
    "    # select prefered columns\n",
    "    remove_columns(stores_train, ['store_id','year','store_name','sales_channel_name','grunnkrets_id','address'])\n",
    "\n",
    "    # Divide data into train and test set\n",
    "    temp_x = stores_train.drop('revenue', axis=1)\n",
    "    temp_y = stores_train['revenue']\n",
    "\n",
    "    _, x_test, _, y_true = train_test_split(temp_x, temp_y, test_size=0.20, random_state=2)\n",
    "\n",
    "\n",
    "    # Preprocess/Clean data\n",
    "    quantile_storeType_vs_revenue(stores_train,i*0.01, 0.86)\n",
    "    #remove_retailers_with_0_revenue(stores_train)\n",
    "\n",
    "    # Divide data into x and y train, and test data for submission\n",
    "    x_train = stores_train.drop('revenue', axis=1)\n",
    "    y_train = stores_train['revenue']\n",
    "\n",
    "\n",
    "    # Convert from object type to numerical\n",
    "    x_train = convert_DType_LGBM(x_train)\n",
    "    x_test = convert_DType_LGBM(x_test)\n",
    "    # Model\n",
    "    LGBM = lgb.LGBMRegressor(reg_alpha=0.2739452484147049, reg_lambda=9.205287883979267, colsample_bytree= 0.6, subsample=0.8, learning_rate= 0.014, max_depth= 100, num_leaves=449, min_child_samples=242)\n",
    "\n",
    "    # fitting\n",
    "    LGBM.fit(x_train, y_train)\n",
    "    # predicting the test data\n",
    "    pred = LGBM.predict(x_test)\n",
    "    for j in range(len(pred)):\n",
    "        if pred[j] < 0.0:\n",
    "            pred[j] = 0.0\n",
    "    print(f\"for upper limit {round((i*0.01), 2)}, rmsle = {round(rmsle(y_true,pred), 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict test and submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_train = pd.read_csv('data/stores_train.csv')\n",
    "stores_test = pd.read_csv('data/stores_test.csv')\n",
    "test = stores_test.copy()\n",
    "\n",
    "# Preprocess/Clean data\n",
    "remove_columns(stores_train, ['store_id','year','store_name','sales_channel_name','grunnkrets_id','address'])\n",
    "remove_columns(test, ['store_id','year','store_name','sales_channel_name','grunnkrets_id','address'])\n",
    "quantile_storeType_vs_revenue(stores_train,0.02, 0.86)\n",
    "#remove_retailers_with_0_revenue(stores_train)\n",
    "\n",
    "# Divide data into x and y train, and test data for submission\n",
    "x_train = stores_train.drop('revenue', axis=1)\n",
    "y_train = stores_train['revenue']\n",
    "\n",
    "# Convert from object type to numerical\n",
    "x_train = convert_DType_LGBM(x_train)\n",
    "test = convert_DType_LGBM(test)\n",
    "\n",
    "# Model and fitting\n",
    "LGBM = lgb.LGBMRegressor()\n",
    "LGBM.fit(x_train, y_train)\n",
    "\n",
    "# Predict test-data-set\n",
    "pred_test_LGBM = LGBM.predict(test)\n",
    "\n",
    "# remove negative values\n",
    "for i in range(len(pred_test_LGBM)):\n",
    "    if pred_test_LGBM[i] < 0.0:\n",
    "        print(i)\n",
    "        pred_test_LGBM[i] = 0.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the predicition to file\n",
    "writeResultToFile(stores_test, pred_test_LGBM, \"LGBM_02_86_precentile_storeType_lat_long_chain_mall_plaace_hier_id\")\n",
    "\n",
    "# Verify format of submission file\n",
    "submissionVery = pd.read_csv('submissionFiles/LGBM_02_86_precentile_storeType_lat_long_chain_mall_plaace_hier_id.csv')\n",
    "submissionVery.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _____ Random Forest Regressor _____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load, preprocess and convert data to correct format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and test data\n",
    "stores_train = pd.read_csv('data/stores_train.csv')\n",
    "stores_test = pd.read_csv('data/stores_test.csv')\n",
    "\n",
    "# Preprocess/Clean data\n",
    "remove_columns(stores_train, ['store_id','year','store_name','sales_channel_name','address','chain_name','mall_name'])\n",
    "remove_columns(stores_test, ['store_id','year','store_name','sales_channel_name','address','chain_name','mall_name'])\n",
    "#remove_retailers_with_0_revenue(stores_train)\n",
    "quantile_storeType_vs_revenue(stores_train,0.10, 0.80)\n",
    "\n",
    "# Divide data into x and y train\n",
    "x_train = stores_train.drop('revenue', axis=1)\n",
    "y_train = stores_train['revenue']\n",
    "x_test = stores_test.copy()\n",
    "\n",
    "# Convert from object type to numerical\n",
    "#train set\n",
    "cat_columns = x_train.select_dtypes(['object']).columns\n",
    "x_train[cat_columns] = x_train[cat_columns].apply(lambda x: pd.factorize(x)[0])\n",
    "#test set\n",
    "cat_columns = x_test.select_dtypes(['object']).columns\n",
    "x_test[cat_columns] = x_test[cat_columns].apply(lambda x: pd.factorize(x)[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "RFR = RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "# Fitting\n",
    "RFR.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test RFR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting the training data set as a pin pointer\n",
    "pred_train_RFR = RFR.predict(x_train)\n",
    "print(rmsle(y_train, pred_train_RFR))\n",
    "print(RFR.score(x_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict test and submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_RFR = RFR.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to file\n",
    "writeResultToFile(stores_test, pred_test_RFR, \"RFR_10_80_percentile\")\n",
    "\n",
    "# Verify format of submission file\n",
    "submissionVery = pd.read_csv('submissionFiles/RFR_10_80_percentile.csv')\n",
    "submissionVery.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emil modeller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pythons stuff emil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some feature moding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modding data...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Interpretations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lime stuff in python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PDP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Final improved models/predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y_true, y_pred):\n",
    "    return metrics.mean_squared_log_error(y_true, y_pred)**0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna\n",
    "\n",
    "optuna code is copied from: https://towardsdatascience.com/kagglers-guide-to-lightgbm-hyperparameter-tuning-with-optuna-in-2021-ed048d9838b5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stores_train = pd.read_csv('data/stores_train.csv')\n",
    "\n",
    "# select prefered columns\n",
    "remove_columns(stores_train, ['store_id','year','store_name','sales_channel_name','grunnkrets_id','address'])\n",
    "\n",
    "# Divide data into train and test set\n",
    "#temp_x = stores_train.drop('revenue', axis=1)\n",
    "#temp_y = stores_train['revenue']\n",
    "\n",
    "#_, x_test, _, y_true = train_test_split(temp_x, temp_y, test_size=0.20, random_state=1)\n",
    "\n",
    "\n",
    "# Preprocess/Clean data\n",
    "quantile_storeType_vs_revenue(stores_train,0.02, 0.86)\n",
    "#remove_retailers_with_0_revenue(stores_train)\n",
    "\n",
    "# Divide data into x and y train, and test data for submission\n",
    "x_train = stores_train.drop('revenue', axis=1)\n",
    "y_train = stores_train['revenue']\n",
    "\n",
    "\n",
    "# Convert from object type to numerical\n",
    "x_train = convert_DType_LGBM(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial,x_train=x_train,y_train=y_train):\n",
    "    param_grid = {\n",
    "        # \"device_type\": trial.suggest_categorical(\"device_type\", ['gpu']),\n",
    "        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [10000]),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 3000, step=20),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 200, 10000, step=100),\n",
    "        \"lambda_l1\": trial.suggest_int(\"lambda_l1\", 0, 100, step=5),\n",
    "        \"lambda_l2\": trial.suggest_int(\"lambda_l2\", 0, 100, step=5),\n",
    "        \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 15),\n",
    "        \"bagging_fraction\": trial.suggest_float(\n",
    "            \"bagging_fraction\", 0.2, 0.95, step=0.1\n",
    "        ),\n",
    "        \"bagging_freq\": trial.suggest_categorical(\"bagging_freq\", [1]),\n",
    "        \"feature_fraction\": trial.suggest_float(\n",
    "            \"feature_fraction\", 0.2, 0.95, step=0.1\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1121218)\n",
    "\n",
    "    cv_scores = np.empty(5)\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(x_train, y_train)):\n",
    "        X_train, X_test = x_train.iloc[train_idx], x_train.iloc[test_idx]\n",
    "        y_train, y_test = y_train[train_idx], y_train[test_idx]\n",
    "\n",
    "        model = lgb.LGBMRegressor(**param_grid)\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            eval_set=[(X_test, y_test)]\n",
    "        )\n",
    "        preds = model.predict_proba(X_test)\n",
    "        cv_scores[idx] = log_loss(y_test, preds)\n",
    "\n",
    "    return np.mean(cv_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"minimize\", study_name=\"LGBM Regressor\")\n",
    "func = lambda trial: objective(trial)\n",
    "study.optimize(func, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('MLvenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64f6ffda83557eb7321e159cda30de9eec3ce84177871a025b9d87d367aa2cef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
